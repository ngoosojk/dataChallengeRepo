{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "049ae877-9f02-4272-b9bc-0d2ce1804770",
   "metadata": {},
   "source": [
    "# Tutorial 1: Data preprocessing\n",
    "https://astronomers.skatelescope.org/ska-science-data-challenge-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcdae23-9c0e-4b97-9eac-d09ce661950a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e668a6-b708-4e61-9b6e-aea0906b02bf",
   "metadata": {},
   "source": [
    "### Introdction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b572371-6a35-45da-bbe5-5cad195857ce",
   "metadata": {},
   "source": [
    "This notebook will show how to process simulated astronomy images, which would invlove the following:\n",
    "1. [Primary Beam Correction](https://www-astro.physics.ox.ac.uk/~ianh/3GC3_sims/3/entry-20130203-135540/index.html):\n",
    "\n",
    "Primary beam (PB) can be thought of as the sensitivity of an instrument as a function of direction. For example, an array of parabolic dishes (img1) has maximum sensitivity in the direction which they are pointing (typically the pointing center), and the sensitivity drops off away from that direction. In the figure below, the blue line depicts the gain of the antenna as a function of angle. The gain varies from 0 to 1, and is maximum along the direction that the antenna is pointing, and reduces as you move away from the pointing centre reaching a minimum at 90 degrees. \n",
    "\n",
    "<center><img src=\"pics/pb.png\" width=\"300\" height=\"150\" ></center><h4 align=\"center\">Img1</h4> \n",
    "\n",
    "\n",
    "So now the question becomes how much sensitivity/accuracy are we willing to sacrifice to obtain more sources. As a rule of thumb, we can take half of the angular distance from the phase center, The image below (img2) shows the same primary beam gain as img1 - we usually restrict our imaging to the inner 50% of the primary beam.\n",
    "\n",
    "<center><img src=\"pics/th.png\" width=\"300\" height=\"150\"></center><h4 align=\"center\">Img2</h4> \n",
    "\n",
    "\n",
    "\n",
    "2. [Source Finding](https://arxiv.org/pdf/1910.03631.pdf#:~:text=Source%2Dfinding%20usually%20involves%20identifying,the%20signal%20from%20the%20source.)\n",
    "\n",
    "Source finding is a process of identifying astronomical sources from an image, against some estimated background.\n",
    "This can be problematic in the radio regime, owing to the presence of noise, and various other systematic artefacts, which can interfere with the signal from the source. Typically one can improve the signal to noise of an image by spending more time observing the target, but this is not always possible for various reasons (telescope schedule etc.).\n",
    "\n",
    "One of the most used algorithms for source finding is the Python Blob Detector and Source-Finder1 (PyBDSF), which works as follows: After reading the image, it performs some pre-processing, for example computing the image statistics. Using a constant threshold for separating the source and noise pixels, the\n",
    "local background @@@rms and mean images are computed. Adjacent islands of source emission are identified, after which each island is fit with multiple Gaussians or Cartesian shapelets. Img3 shows multiple sources with gaussian distributions.\n",
    "\n",
    "<center><img src=\"pics/gd.png\" width=\"200\" height=\"100\"></center></center> <h4 align=\"center\">Img3</h4> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8a4ba8-e901-404e-8415-b3b6b68d4a15",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b109094-6959-4ddd-9196-919b53521417",
   "metadata": {},
   "source": [
    "### Let us get started with the Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c170e829-e1e2-4721-9c49-ac7270d60bab",
   "metadata": {},
   "source": [
    "First we import some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9696fc4c-1149-49f8-b730-725f764257b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 1___\n",
    "\n",
    "# General packages\n",
    "import os # The OS module in Python provides functions for creating and removing a directory\n",
    "import numpy as np # For performing comprehensive mathematical functions, like generating random number\n",
    "import matplotlib # For matplotlib helper functions\n",
    "import matplotlib.pyplot as plt  # For drawing useful graphs, such as bar graphs\n",
    "\n",
    "## Astronomy related packages\n",
    "from astropy.io import fits # A package provides access to FITS files. \n",
    "# FITS (Flexible Image Transport System) is a portable file standard widely used in the astronomy community to store images and tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e02b4e0-5ace-41fc-9309-07de014579ea",
   "metadata": {},
   "source": [
    "The above statements define the prefixes 'np' and 'plt' which will be used to identify numpy and matplotlib.pyplot functions respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd26b9-0cef-468f-b28e-21bafeccc7af",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60587e1c-8fb6-4de6-b9aa-15169b1c8ef0",
   "metadata": {},
   "source": [
    "<b><i> Reading in data </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff0e4b-4f4a-4917-81d7-0a5dabc9abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.utils.data import get_pkg_data_filename # Retrieves a data file from the standard locations for the package and provides a local filename for the data.\n",
    "\n",
    "fits1400_1000h = get_pkg_data_filename(os.path.abspath(\"../data/sample_images/1400mhz_1000h.fits\")) # Reading fits file\n",
    "fits1400_pb = get_pkg_data_filename(os.path.abspath(\"../data/sample_images/1400mhz_pb.fits\")) # Reading the primary beam file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189416f1-2d37-49ff-b5e5-3d887c83fc6b",
   "metadata": {},
   "source": [
    "---\n",
    "**Exercise 1:** get the path for the other 2 image frequencies with their pb fits files\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b6ce8-cf09-4988-ad64-4ca0ace45742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- code goes here --\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f80ab-2c2b-49d7-bdb8-e021be29e009",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892901da-ab8e-4131-8c7e-a7843d6daf15",
   "metadata": {},
   "source": [
    "<b><i> Examining data </i></b> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e87e2e0-ae56-4198-8d81-d8ee783e859d",
   "metadata": {},
   "source": [
    "First let's take a look at the shape of the fits files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859deb4-d52b-489c-802a-9e4491dc6b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fits.info(fits1400_1000h))\n",
    "print()\n",
    "print(fits.info(fits1400_pb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc2c23-956d-44d4-8791-f005d1a5bc4b",
   "metadata": {},
   "source": [
    "The data has two extra dimensions that need to be deleted, therefore we will need to reshape those files in the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a046e6-be88-4d16-94ed-fc8e08de3da6",
   "metadata": {},
   "source": [
    "---\n",
    "**Exercise 2:** Display the information for the other image frequencies with their primary beam  files\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ba979-196d-4f69-8ea0-e57d29288762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- code goes here --\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba813d67-a2e1-4448-9c88-193ab8ea63d3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d8c1d-4195-4325-bbc2-52490764d41f",
   "metadata": {},
   "source": [
    "<b><i> Reshape the data </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b660223-72f2-412a-a235-7c9c8c5ade4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1400_1000h = np.squeeze(fits.getdata(fits1400_1000h, ext=0)) \n",
    "# removes the extra dimension in (5204, 4776, 1, 1)\n",
    "print(img1400_1000h.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c817c4a8-d758-4df3-83ab-946c818bdcbf",
   "metadata": {},
   "source": [
    "<b><i> summary statistics </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8681a5-af7f-4615-a71d-57f5f3bf3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min:', np.min(img1400_1000h))\n",
    "print('Max:', np.max(img1400_1000h))\n",
    "print('Mean:', np.mean(img1400_1000h))\n",
    "print('Stdev:', np.std(img1400_1000h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b2abb1-5dc3-4d4d-9c7d-53650952a8f7",
   "metadata": {},
   "source": [
    "you can do it for the other two images, no one will stop you !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eca4e6-6fc3-4d72-b704-efc2c0f3957c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<b><i> Visualising the simulated image </i></b> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c8213-29cb-42aa-8188-a899c99c7488",
   "metadata": {},
   "source": [
    "First, let us do the histgram of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6755dcd-dc8e-435c-98c0-c20bb8747b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bins = np.histogram(img1400_1000h, bins=500, range=[-1e-6, 4e-6])\n",
    "bins = (bins[:-1] + bins[1:])/2.\n",
    "w = bins[1] - bins[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "ax.bar(bins, hist, width=w)\n",
    "plt.xlabel(\"Pixel intensity\", size= 16)\n",
    "plt.ylabel(\"Number of pixels\", size= 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c688341-b9f6-48c2-9264-9b1a0fc940be",
   "metadata": {},
   "source": [
    "The above histogram of the simulated image shows that we have a positive-skewed Gaussian distribution, with a peak around 0 and a long positive tail. This is because :\n",
    "\n",
    "    1- The noise pixels will have close to zero mean, and will primarily contribute to the histogram distribution around 0.\n",
    "    2- The real astronomical sources in the image cannot have a negative flux value, and hence contribute to the long positive tail of the Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeade94-27de-4d81-b9cc-235e30a2499c",
   "metadata": {},
   "source": [
    "Therefore, to visualize the sources of the radio image without much noise we need to use clipped standard deviation (clip_STD) instead of the normal STD.\n",
    "\n",
    "Therefore in order to effectively visualize the image, we need to estimate the standard deviation of the distribution accurately. However due to the long positive tail, calculating the standard deviation over the entire histogram will be biased toward positive values. Therefore we need to perform sigma clipping to reject outliers before calculating the standard deviation for a more accurate representation.\n",
    "\n",
    "[Sigma clipping](https://www.gnu.org/software/gnuastro/manual/html_node/Sigma-clipping.html) is a process of iteratively ignoring points that lie outside a threshold of mean +/- std. After ignoring the outliers, the mean and standard deviation are re-calculated and so on. The process is stopped after a specified number of iterations or if there is no longer any meaningful improvement in the mean or standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b443b88-ef1b-4610-83db-f7df7f8cba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "ax.bar(bins, hist, width=w)\n",
    "\n",
    "def sigma_clip(inpdata, sigma_threshold=3.0, niter=10):\n",
    "    tmpdata = np.copy(inpdata)\n",
    "    nn = 0\n",
    "    while nn < niter:\n",
    "        mean = np.mean(tmpdata)\n",
    "        std = np.std(tmpdata)\n",
    "        min_thresh = mean - sigma_threshold*std\n",
    "        max_thresh = mean + sigma_threshold*std\n",
    "        \n",
    "        cond = (tmpdata > min_thresh) & (tmpdata < max_thresh)\n",
    "        \n",
    "        tmpdata = tmpdata[cond]\n",
    "        \n",
    "        \n",
    "        print(f\"Mean is: {mean:.10f}\")\n",
    "        print(f\"Std is:  {std: .10f}\")\n",
    "        \n",
    "        \n",
    "        # Plot the mean+sigma_threshold in a sequential colormap\n",
    "        cmap = matplotlib.cm.get_cmap('Spectral')\n",
    "        color = cmap(float(nn/niter))\n",
    "        \n",
    "        ax.axvline(mean + sigma_threshold*std, label=f'Iteration {nn}', c=color, linewidth=2)\n",
    "        \n",
    "        nn += 1\n",
    "        \n",
    "sigma_clip(img1400_1000h, 3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322de648-3568-4646-b80b-ee2afb5d67b1",
   "metadata": {},
   "source": [
    "The horizontal lines correspond to the calculated standard deviation every iteration. With every subsequent iteration the calculated standard deviation moves closer to the \"true\" standard deviation of the underlying noise distribution, eventually converging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0b63ae-ba43-4005-90ea-d51e9c1ad8d6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603ea2e1-1a5b-4e60-a908-b846598f0a97",
   "metadata": {},
   "source": [
    "### Comparing the two images before and after the clipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ced78-6dac-45c4-afa1-faddf7d3d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sigmaclip # For better image visualization, we will be using this built function, instead of the function we defined above\n",
    "\n",
    "std = np.std(img1400_1000h) # getting the normal SD (before clipping)\n",
    "clip_std = np.std(sigmaclip(img1400_1000h)[0]) # getting the clipped SD (after clipping)\n",
    "print(std, clip_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5e0e4c-d364-4289-b54d-156df6d1ae78",
   "metadata": {},
   "source": [
    "Before we visualize the image we will need to use **SymLogNorm** so that we can normalize the image with logscale, and deal with negative (-) pixel values. as for its parameters:   \n",
    "\n",
    "    1- vmin: minus the (STD or clip_STD)\n",
    "    2- vmax: (STD or clip_STD) * 10\n",
    "    3- linthresh: (STD or clip_STD) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c17627-0cc1-43b0-a67d-39a5a843a6ac",
   "metadata": {},
   "source": [
    "now we will show the difference between using STD, and clip_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad93c262-fa39-4412-abf1-0769fb02cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import SymLogNorm\n",
    "\n",
    "# https://github.com/HorizonIITM/PythonForAstronomy/blob/master/FITS%20Handling/PythonforAstronomy3.ipynb\n",
    "plt.figure(figsize=(20, 10)) # setting up the size of the image\n",
    "plt.imshow(img1400_1000h, origin='lower', norm=SymLogNorm(vmin= -std, vmax=std*10, linthresh=std), cmap='inferno') # show the image\n",
    "plt.savefig('pics/beforeSTD.png') # saving the image, we need to save the image so we can compare it after we perform PB correction\n",
    "plt.colorbar()# plotting the color bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5df240-b1aa-4684-a23e-de944bea9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import SymLogNorm\n",
    "\n",
    "# https://github.com/HorizonIITM/PythonForAstronomy/blob/master/FITS%20Handling/PythonforAstronomy3.ipynb\n",
    "plt.figure(figsize=(20, 10)) # setting up the size of the image\n",
    "plt.imshow(img1400_1000h, origin='lower', norm=SymLogNorm(vmin= -clip_std, vmax=clip_std*10, linthresh=clip_std), cmap='inferno') # show the image\n",
    "plt.savefig('pics/beforeCSTD.png') # saving the image, we need to save the image so we can compare it after we perform PB correction\n",
    "plt.colorbar()# plotting the color bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70acb862-bb32-438a-8266-fb658c0d72d4",
   "metadata": {},
   "source": [
    "We can see that the difference is clear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00b119-7c0d-49c4-84ba-9bb912da8be6",
   "metadata": {},
   "source": [
    "---\n",
    "**Exercise 3:** Display the other 2 image frequencies \n",
    "<br>\n",
    "hint: you will need to adjust the parameter for the 'SymLogNorm' function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4654f-1afd-4db6-84c0-a4daaf337021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- code here --\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c370b4f-1673-4028-af1b-b56b1ec71844",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f426cf2-4adb-4405-85c1-264e0f909c19",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "now we will do the following:\n",
    "1) Preprocess images (correct PB)\n",
    "2) Cropping the image for training: In order for us to train the ML models we will need to separate the data into training and testing. It is essential for the training data to not overlap with the testing to avoid data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2f2c85-0a7c-4629-b575-ffc9b69adfcb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe9310-0349-4445-bef5-4ceba1c9eafa",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88fb5d5-dc3a-4af2-9b14-44bfedd39a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.pre.sdc1_image import Sdc1Image # importing Sdc1Image class from the sdc1_image.py python file from the source/pre folder\n",
    "from source.path import image_path, pb_path # importing some path functions from the path.py python file from the source folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176ead8-bcf2-41b9-a0ab-f668c001b34f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2e49b1-d1de-4d42-8355-ad5067652abd",
   "metadata": {},
   "source": [
    "first let us define a new image from the Sdc1Image class from the sdc1_image.py file, and also the frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd9edd-d9c3-4964-a6ce-d6a99aa5e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 1400 \n",
    "new_image = Sdc1Image(freq, image_path(freq), pb_path(freq)) # define a new instance of Sdc1Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dff28a-6bce-430c-9757-cd6f4a33e9f4",
   "metadata": {},
   "source": [
    "Defining the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c773f79c-0bff-4892-abf9-7fb60fbcdbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    \"\"\"\n",
    "    Perform preprocessing steps:\n",
    "        1) Create PB-corrected image (image.pb_corr_image)\n",
    "        2) Output separate training image (image.train)\n",
    "    \"\"\"\n",
    "    image._prep = False\n",
    "    image._create_pb_corr() # performing PB correciton\n",
    "    image._create_train() # cropping the data\n",
    "    image._prep = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab3f23-9691-4edf-a73c-abcd4970d66c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess(new_image) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab46e9b-6c7a-413f-90d9-5a8dd3a251dc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896e40e8-fcea-4c0b-b3a7-a6f35e3d969d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Output visualization: \n",
    "now we will try to visualize the following preprocessed images:\n",
    "\n",
    "- corrected image (After the PB correction)\n",
    "- Before and after the correction\n",
    "- Training (cropped) image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2841bf1c-0623-4a2e-8ea1-70ff904ae5a9",
   "metadata": {},
   "source": [
    "<b><i> corrected image </i></b> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b0f0c-b03f-45dd-9323-ab0cb4eb9672",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1400_1000h_corrected = fits.getdata(new_image.pb_corr_image, ext=0)\n",
    "print(img1400_1000h_corrected.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e7d93-7ca1-4829-a3c3-519db3acbbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1400_1000h_corrected = img1400_1000h_corrected.reshape(img1400_1000h_corrected.shape[2:])\n",
    "print(img1400_1000h_corrected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930f3ac-be3e-4b3e-8ccc-6aa7fd10f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(img1400_1000h_corrected, origin='lower', norm=SymLogNorm(vmin=-clip_std, vmax=clip_std*10, linthresh=clip_std), cmap='inferno')\n",
    "plt.savefig('pics/after.png')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0620eee-37ca-4205-9e4d-b2b181e98177",
   "metadata": {},
   "source": [
    "<b><i> Before & After the correction </i></b> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddce394-ca08-4f4f-9637-7f43588d9bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "def make_mov(fnames=[],output='animation.gif',fps=4):\n",
    "        \n",
    "    with imageio.get_writer(output, mode='I', fps=fps) as writer:\n",
    "        for file in fnames:\n",
    "            image = imageio.imread(file)\n",
    "            writer.append_data(image)\n",
    "            \n",
    "make_mov(fnames=['pics/beforeCSTD.png','pics/after.png'],output='pics/difference.gif',fps=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9552962-8742-41d6-ae67-63e904da9cf2",
   "metadata": {},
   "source": [
    "<img src=\"pics/difference.gif\" width=\"2000\" height=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dd4866-7cad-4ccc-840f-a58bd9c7c8af",
   "metadata": {},
   "source": [
    "The above image is blinking between the images before and after PB correction. Since we are dealing with an image that falls within the 50% point of the PB (as mentioned earlier), the visual differences between the before and after image will not be very large, but the measured fluxes will now be scientifically accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731ad53e-af0a-465a-9d1c-31ea4508f229",
   "metadata": {},
   "source": [
    "<b><i> Training (cropped) image </i></b> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e9c8f-70fa-4f4a-886e-799587002d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1400_1000h_train = fits.getdata(new_image.train, ext=0)\n",
    "img1400_1000h_train = img1400_1000h_train.reshape(img1400_1000h_train.shape[2:])\n",
    "\n",
    "print(img1400_1000h_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3e6c4-c104-479f-b7e2-8e079fa0bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(img1400_1000h_train, origin='lower', norm=SymLogNorm(vmin=-clip_std, vmax=clip_std*10, linthresh=clip_std), cmap='inferno')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92c1f4-2a4d-4fe9-9228-830250c99e79",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd615408-581d-4dae-bf37-34569bc165dd",
   "metadata": {},
   "source": [
    "### Source finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7cf560-eae3-4ebe-83f2-27a7df19f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.utils.source_finder import SourceFinder\n",
    "from source.path import write_df_to_disk, train_source_df_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a16c00-4087-4591-b444-85350d9545aa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bbc51e-7c81-4a4c-a73e-dda85bc18163",
   "metadata": {},
   "source": [
    "<b><i> Source finding on the training image </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86859f7-9b8d-475c-800c-d3003042685c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sources_training = {}\n",
    "source_finder = SourceFinder(new_image.train)\n",
    "sl_df = source_finder.run()\n",
    "\n",
    "sources_training[new_image.freq] = sl_df\n",
    "\n",
    "# (Optional) Write source list DataFrame to disk\n",
    "write_df_to_disk(sl_df, train_source_df_path(new_image.freq))\n",
    "\n",
    "# Remove temp files:\n",
    "source_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f5a2a-5acc-4345-a9e9-e9e9940783dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sources_training[1400].head(2))\n",
    "print()\n",
    "print(sources_training[1400].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b56708c-b323-448f-b544-166b7b6060d0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4651157-a30b-4bc2-84d9-a5e953464a0e",
   "metadata": {},
   "source": [
    "<b><i> Source finding on the whole image </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ce34d-9891-44de-a200-72e0028017db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sources_full = {}\n",
    "source_finder = SourceFinder(new_image.pb_corr_image)\n",
    "sources_full[new_image.freq] = source_finder.run(thresh_isl=4.0, thresh_pix=5.0)\n",
    "\n",
    "\n",
    "# Remove temp files:\n",
    "source_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e305eaf-4974-40eb-82d1-160676e11913",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sources_full[1400].head(2))\n",
    "print()\n",
    "print(sources_full[1400].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d556c-eb86-47ee-85b6-9187617d43bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89308ce8-ddc9-4310-9037-79718fd8f258",
   "metadata": {},
   "source": [
    "Saving the data frames for the next tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44290d9-8497-4bcd-8541-3794064cf94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store  sources_training\n",
    "%store sources_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f537c7-4a0c-4227-90e6-9b4bbc951963",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801729cd-47da-4c99-8361-7d186959fab1",
   "metadata": {},
   "source": [
    "Repeat all above for the other two frequencies "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DC2_ker",
   "language": "python",
   "name": "dc2_ker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
