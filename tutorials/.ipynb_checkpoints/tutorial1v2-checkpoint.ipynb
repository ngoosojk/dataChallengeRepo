{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "049ae877-9f02-4272-b9bc-0d2ce1804770",
   "metadata": {},
   "source": [
    "# Tutorial 1: Data preprocessing\n",
    "https://astronomers.skatelescope.org/ska-science-data-challenge-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcdae23-9c0e-4b97-9eac-d09ce661950a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e668a6-b708-4e61-9b6e-aea0906b02bf",
   "metadata": {},
   "source": [
    "### Introdction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b572371-6a35-45da-bbe5-5cad195857ce",
   "metadata": {},
   "source": [
    "This notebook will show how to process astronomy images, which involves corectting primary beams, and cropping out the training area for the machine learning (ML) model. It will also include how to find the sources for the training images (@@@ why only the training, yes I suppose because they already have a ground truth prepared)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6311266b-04d5-4db7-8d71-6f17dd7cfda3",
   "metadata": {},
   "source": [
    "This notebook will cover the following:\n",
    "  1) Preprocess images (correct PB) and crop out the training area for building ML model\n",
    "  2) Find sources in the PB-corrected training images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8a4ba8-e901-404e-8415-b3b6b68d4a15",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b72c7-8810-4240-8d76-fd3afd1fba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# from ska.sdc1.models.sdc1_image import Sdc1Image\n",
    "import bdsf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.io import fits # define\n",
    "from astropy.wcs import WCS # define\n",
    "from astropy import units as u #define\n",
    "from astropy.coordinates import SkyCoord #define\n",
    "from astropy.nddata.utils import Cutout2D # define\n",
    "# from MontagePy.main import * # http://montage.ipac.caltech.edu/MontageNotebooks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd26b9-0cef-468f-b28e-21bafeccc7af",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60587e1c-8fb6-4de6-b9aa-15169b1c8ef0",
   "metadata": {},
   "source": [
    "<b><i> get the path </i></b> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff0e4b-4f4a-4917-81d7-0a5dabc9abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits1400_1000h = get_pkg_data_filename(\"data/sample_images/1400mhz_1000h.fits\")\n",
    "fits1400_pb = get_pkg_data_filename(\"data/sample_images/1400mhz_pb.fits\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189416f1-2d37-49ff-b5e5-3d887c83fc6b",
   "metadata": {},
   "source": [
    "---\n",
    "**Exercise 1:** get the path for the 2 other image frequencies with their pb fits files\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b6ce8-cf09-4988-ad64-4ca0ace45742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- code goes here --\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f80ab-2c2b-49d7-bdb8-e021be29e009",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274eb56d-002f-4917-abe1-e7a26145c017",
   "metadata": {},
   "source": [
    "@@ Questions, \n",
    "- I read that the fits images are corrected PB images, then why do we need *fits_pb* 1400mhz_pb fits flies  ? ? ? ? ? ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c54263-6bfb-4c5a-b5d5-303e2e1b65b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892901da-ab8e-4131-8c7e-a7843d6daf15",
   "metadata": {},
   "source": [
    "<b><i> Displaying file informations </i></b> \n",
    "\n",
    "like the shape of the fits files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859deb4-d52b-489c-802a-9e4491dc6b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fits.info(fits1400_1000h))\n",
    "print()\n",
    "print(fits.info(fits1400_pb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a046e6-be88-4d16-94ed-fc8e08de3da6",
   "metadata": {},
   "source": [
    "---\n",
    "**Exercise 2:** Display the info for the other image frequencies with thier pb fits files\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ba979-196d-4f69-8ea0-e57d29288762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- code goes here --\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba813d67-a2e1-4448-9c88-193ab8ea63d3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d8c1d-4195-4325-bbc2-52490764d41f",
   "metadata": {},
   "source": [
    "<b><i> Display the shape </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b660223-72f2-412a-a235-7c9c8c5ade4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1400_1000h = fits.getdata(fits1400_1000h, ext=0)\n",
    "img1400_1000h = img1400_1000h.reshape(4776, 5204)\n",
    "\n",
    "print(img1400_1000h.shape)\n",
    "# print(img_1000h[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c817c4a8-d758-4df3-83ab-946c818bdcbf",
   "metadata": {},
   "source": [
    "<b><i> summary statistics </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8681a5-af7f-4615-a71d-57f5f3bf3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min:', np.min(img1400_1000h))\n",
    "print('Max:', np.max(img1400_1000h))\n",
    "print('Mean:', np.mean(img1400_1000h))\n",
    "print('Stdev:', np.std(img1400_1000h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b2abb1-5dc3-4d4d-9c7d-53650952a8f7",
   "metadata": {},
   "source": [
    "you can do it for the other two images, no one will stop you !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eca4e6-6fc3-4d72-b704-efc2c0f3957c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<b><i> Visualise the image </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5df240-b1aa-4684-a23e-de944bea9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "# https://github.com/HorizonIITM/PythonForAstronomy/blob/master/FITS%20Handling/PythonforAstronomy3.ipynb\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(img1400_1000h, cmap='PuBu_r', norm=LogNorm())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd600d-70d9-4b69-9861-72debc55b205",
   "metadata": {},
   "source": [
    "@Q: is there is no why we can turn the above image like the one from the website ? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00b119-7c0d-49c4-84ba-9bb912da8be6",
   "metadata": {},
   "source": [
    "---\n",
    "**Exercise 3:** Display the 2 other image frequencies \n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4654f-1afd-4db6-84c0-a4daaf337021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- code here --\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c370b4f-1673-4028-af1b-b56b1ec71844",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f426cf2-4adb-4405-85c1-264e0f909c19",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "now we will do the following:\n",
    "1) Preprocess images (correct PB)\n",
    "2) crop out the training area for building ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2f2c85-0a7c-4629-b575-ffc9b69adfcb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe9310-0349-4445-bef5-4ceba1c9eafa",
   "metadata": {},
   "source": [
    "improting some packges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88fb5d5-dc3a-4af2-9b14-44bfedd39a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from MontagePy.main import mGetHdr, mProjectQL\n",
    "\n",
    "from source.utils.image_utils import (\n",
    "    crop_to_training_area,\n",
    "    get_image_centre_coord,\n",
    "    get_pixel_value_at_skycoord,\n",
    "    save_subimage,\n",
    ")\n",
    "\n",
    "from source.pre.sdc1_image import Sdc1Image\n",
    "from path import image_path, pb_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176ead8-bcf2-41b9-a0ab-f668c001b34f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2e49b1-d1de-4d42-8355-ad5067652abd",
   "metadata": {},
   "source": [
    "first let us define a new image from the Sdc1Image in sdc1_image.py, and also the frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609bf889-3a4b-4f07-a568-173d4392b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 1400\n",
    "new_image = Sdc1Image(freq, image_path(freq), pb_path(freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a06f6f-4955-4ffe-a8df-28e258981d0f",
   "metadata": {},
   "source": [
    "first let us define the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a048cd6-aba1-4abd-9d26-c1de789f2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_pb_corr(image):\n",
    "    \"\"\"\n",
    "    Apply PB correction to the image at image.path, using the primary beam\n",
    "    file at image.pb_path.\n",
    "\n",
    "    This uses Montage to regrid the primary beam image to the same pixel scale\n",
    "    as the image to be corrected.\n",
    "    \"\"\"\n",
    "    image._pb_corr_image = None\n",
    "\n",
    "    # Establish input image to PB image pixel size ratios:\n",
    "    with fits.open(image.pb_path) as pb_hdu:\n",
    "        pb_x_pixel_deg = pb_hdu[0].header[\"CDELT2\"]\n",
    "    with fits.open(image.path) as image_hdu:\n",
    "        x_size = image_hdu[0].header[\"NAXIS1\"]\n",
    "        x_pixel_deg = image_hdu[0].header[\"CDELT2\"]\n",
    "\n",
    "    ratio_image_pb_pix = (x_size * x_pixel_deg) / pb_x_pixel_deg\n",
    "    coord_image_centre = get_image_centre_coord(image.path)\n",
    "\n",
    "    if ratio_image_pb_pix < 2.0:\n",
    "        # Image not large enough to regrid (< 2 pixels in PB image);\n",
    "        # apply simple correction\n",
    "        pb_value = get_pixel_value_at_skycoord(image.pb_path, coord_image_centre)\n",
    "        image._apply_pb_corr(pb_value)\n",
    "        return\n",
    "\n",
    "    with fits.open(image.pb_path) as pb_hdu:\n",
    "        # Create cropped PB image larger than the input image\n",
    "        # TODO: May be inefficient when images get large\n",
    "        size = (\n",
    "            x_size * x_pixel_deg * u.degree * 2,\n",
    "            x_size * x_pixel_deg * u.degree * 2,\n",
    "        )\n",
    "\n",
    "        save_subimage(\n",
    "            image.pb_path,\n",
    "            image._get_pb_cut_path(),\n",
    "            coord_image_centre,\n",
    "            size,\n",
    "            overwrite=True,\n",
    "        )\n",
    "\n",
    "    # Regrid image PB cutout to same pixel scale as input image\n",
    "    mGetHdr(image.path, image._get_hdr_path())\n",
    "\n",
    "    # TODO: mProjectQL better than mProject, which outputs too-small images?\n",
    "    rtn = mProjectQL(\n",
    "        input_file=image._get_pb_cut_path(),\n",
    "        output_file=image._get_pb_cut_rg_path(),\n",
    "        template_file=image._get_hdr_path(),\n",
    "    )\n",
    "    if rtn[\"status\"] == \"1\":\n",
    "        raise ImageNotPreprocessed(\n",
    "            \"Unable to reproject image: {}\".format(rtn[\"msg\"])\n",
    "        )\n",
    "\n",
    "    # Correct Montage output (convert to 32-bit and fill NaNs)\n",
    "    pb_array = image._postprocess_montage_out()\n",
    "\n",
    "    # Apply PB correction and delete temporary files\n",
    "    image._apply_pb_corr(pb_array)\n",
    "    image._cleanup_pb()\n",
    "\n",
    "\n",
    "\n",
    "# @@@ should we reduce this method abit ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642d4ad-f51b-4c55-a613-791d1bbd1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropping out the training area for building ML model\n",
    "def _create_train(image, pad_factor=1.0):\n",
    "    \"\"\"\n",
    "    Create the training image (crop to the frequency-dependent training area)\n",
    "    \"\"\"\n",
    "    image._train = None\n",
    "    train_path = image.path[:-5] + \"_train.fits\" # creating a new path for the training image \n",
    "    crop_to_training_area(image._pb_corr_image, train_path, image.freq, pad_factor)\n",
    "    image._train = train_path\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669291f-1b2f-4abb-9365-b7df78e380b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    \"\"\"\n",
    "    Perform preprocessing steps:\n",
    "        1) Create PB-corrected image (image.pb_corr_image)\n",
    "        2) Output separate training image (image.train)\n",
    "    \"\"\"\n",
    "    image._prep = False\n",
    "    _create_pb_corr(image)\n",
    "    _create_train(image)\n",
    "    image._prep = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a748f20-7d76-4842-831d-60f5fe2af7a7",
   "metadata": {},
   "source": [
    "@@@ I wander why do we need to to cut an area for the training, instead what we can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a7392-4d4c-496b-a545-61482fc3ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ab877-5c80-4fa0-84d1-ff85884fa11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_path(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab3f23-9691-4edf-a73c-abcd4970d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = Sdc1Image(freq, image_path(freq), pb_path(freq))\n",
    "preprocess(new_image) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896e40e8-fcea-4c0b-b3a7-a6f35e3d969d",
   "metadata": {},
   "source": [
    "### now let is visualise the ouput images:\n",
    "- corrected image\n",
    "- trained area image\n",
    "\n",
    "first let us see the path for both images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d77c2-2b1b-4b50-83f5-57b79f141a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"primary corrected image:\\n   \"+new_image.pb_corr_image)\n",
    "print()\n",
    "print(\"trainig image:\\n   \"+new_image.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54917702-4406-4e46-8077-a29b816d2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_path = [new_image.pb_corr_image, new_image.train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ed3fa-8192-46f0-a23c-78c15d28b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for newImg in arr_path:\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    print(fits.info(newImg))\n",
    "    img = fits.getdata(newImg, ext=0)\n",
    "    print(len(img.shape))\n",
    "    if len(img.shape) == 4:\n",
    "        img = img.reshape(img.shape[2:])\n",
    "        print(img.shape)\n",
    "    plt.imshow(img, cmap='PuBu_r', norm=LogNorm())\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51089f-58ed-4f4f-b6db-fe76aedbd3b5",
   "metadata": {},
   "source": [
    "@@@ visually I dont think I can spot the diffrince between the original, and the corrected PB image. what can we do to see that. a sugesstion would be to test both on a ml model, and then check the difference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92c1f4-2a4d-4fe9-9228-830250c99e79",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd615408-581d-4dae-bf37-34569bc165dd",
   "metadata": {},
   "source": [
    "### Source finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7cf560-eae3-4ebe-83f2-27a7df19f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.utils.source_finder import SourceFinder\n",
    "from path import write_df_to_disk, train_source_df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c277a-5bb2-42d1-8a90-b32430afc82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_beam_from_hdu(sFinder):\n",
    "    \"\"\"\n",
    "    Look up the beam information in the header of the SourceFinder's image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with fits.open(sFinder.image_name) as hdu:\n",
    "            beam_maj = hdu[0].header[\"BMAJ\"]\n",
    "            beam_min = hdu[0].header[\"BMIN\"]\n",
    "            beam_pa = 0\n",
    "            return (beam_maj, beam_min, beam_pa)\n",
    "    except IndexError:\n",
    "        raise SourceFinderException(\"Unable to automatically determine beam info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db06f3e8-4c5a-49fc-98fd-1fdd124f3bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_rms_box_from_hdu(sFinder):\n",
    "    \"\"\"\n",
    "    Determine an appropriate RMS box size using the header of the SourceFinder's\n",
    "    image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with fits.open(sFinder.image_name) as hdu:\n",
    "            beam_maj = hdu[0].header[\"BMAJ\"]\n",
    "            pix_per_beam = beam_maj / hdu[0].header[\"CDELT2\"]\n",
    "            return (30 * pix_per_beam, 8 * pix_per_beam)\n",
    "    except IndexError:\n",
    "        raise SourceFinderException(\n",
    "            \"Unable to automatically determine RMS box size\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b892423-66fb-47c4-ac15-4a36c6e6faa3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12620d-5211-42e0-adee-dc984e89f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(sFinder, **kwargs):\n",
    "    import def_run \n",
    "    \"\"\"\n",
    "    Run the source finder algorithm.\n",
    "\n",
    "    Args are the same as for the bdsf.process_image method, with sensible defaults\n",
    "    submitted for any not given.\n",
    "\n",
    "    The 'beam' and 'rms_box' arg defaults are determined from the image header if\n",
    "    not provided.\n",
    "    \"\"\"\n",
    "\n",
    "    sFinder._run_complete = False\n",
    "\n",
    "    # Must switch the executor's working directory to the image directory to\n",
    "    # run PyBDSF, and switch back after the run is complete.\n",
    "    cwd = os.getcwd()\n",
    "    print()\n",
    "    \n",
    "    os.chdir(sFinder.image_dirname)\n",
    "\n",
    "    # Get beam info automatically if not provided\n",
    "    if not def_run.beam:\n",
    "        def_run.beam = _get_beam_from_hdu(sFinder)\n",
    "    if not def_run.rms_box:\n",
    "        def_run.rms_box = _get_rms_box_from_hdu(sFinder)\n",
    "\n",
    "    # Run PyBDSF\n",
    "    try:\n",
    "        bdsf.process_image(\n",
    "            sFinder.image_name,\n",
    "            adaptive_rms_box=def_run.adaptive_rms_box,\n",
    "            advanced_opts=def_run.advanced_opts,\n",
    "            atrous_do=def_run.atrous_do,\n",
    "            psf_vary_do=def_run.psf_vary_do,\n",
    "            psf_snrcut=def_run.psf_snrcut,\n",
    "            psf_snrcutstack=def_run.psf_snrcutstack,\n",
    "            output_opts=def_run.output_opts,\n",
    "            output_all=def_run.output_all,\n",
    "            opdir_overwrite=def_run.opdir_overwrite,\n",
    "            beam=def_run.beam,\n",
    "            blank_limit=def_run.blank_limit,\n",
    "            thresh=def_run.thresh,\n",
    "            thresh_isl=def_run.thresh_isl,\n",
    "            thresh_pix=def_run.thresh_pix,\n",
    "            psf_snrtop=def_run.psf_snrtop,\n",
    "            rms_map=def_run.rms_map,\n",
    "            rms_box=def_run.rms_box,\n",
    "            do_cache=def_run.do_cache,\n",
    "            **kwargs\n",
    "        )\n",
    "    except Exception as e:\n",
    "        # Catch all exceptions to ensure CWD reverted\n",
    "        os.chdir(cwd)\n",
    "        raise e\n",
    "\n",
    "    # Revert current working directory\n",
    "    os.chdir(cwd)\n",
    "    sFinder.clean_tmp()\n",
    "    sFinder._run_complete = True\n",
    "\n",
    "    return sFinder.get_source_df()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a16c00-4087-4591-b444-85350d9545aa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bbc51e-7c81-4a4c-a73e-dda85bc18163",
   "metadata": {},
   "source": [
    "now let us do source finding on the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86859f7-9b8d-475c-800c-d3003042685c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sources_training = {}\n",
    "source_finder = SourceFinder(new_image.train)\n",
    "print(source_finder.image_dirname)\n",
    "sl_df = run(source_finder)\n",
    "\n",
    "sources_training[new_image.freq] = sl_df\n",
    "\n",
    "# (Optional) Write source list DataFrame to disk\n",
    "write_df_to_disk(sl_df, train_source_df_path(new_image.freq))\n",
    "\n",
    "# Remove temp files:\n",
    "source_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ce34d-9891-44de-a200-72e0028017db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sources_full = {}\n",
    "source_finder = SourceFinder(new_image.pb_corr_image)\n",
    "print(source_finder.image_dirname)\n",
    "sl_df = run(source_finder)\n",
    "\n",
    "sources_full[new_image.freq] = sl_df\n",
    "\n",
    "# (Optional) Write source list DataFrame to disk\n",
    "# write_df_to_disk(sl_df, train_source_df_path(new_image.freq))\n",
    "\n",
    "# Remove temp files:\n",
    "source_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f5a2a-5acc-4345-a9e9-e9e9940783dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sources_training)\n",
    "# print(sources_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d556c-eb86-47ee-85b6-9187617d43bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89308ce8-ddc9-4310-9037-79718fd8f258",
   "metadata": {},
   "source": [
    "save the sources_training & sources_full for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44290d9-8497-4bcd-8541-3794064cf94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store  sources_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e49fa7-5121-4f23-96b3-fb12efd1de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store sources_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b954ad-ad1d-44d4-bead-0df3f53e66c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385e938-d736-423f-889c-590b0d60d50d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c2eac-7f01-4a2f-beb9-2462f8619e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1c7d3-8422-49a0-9eee-98203ffe3ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dc1_ker2",
   "language": "python",
   "name": "dc1_ker2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
